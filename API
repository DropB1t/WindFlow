#################################################################################################
#                                  WINDFLOW ACCEPTED SIGNATURES                                 #
#################################################################################################

This file lists all the possible signatures that can be used to create WindFlow operators. In case
you provide a functional logic having a wrong signature during the creation of an operator (through
its builder), you receive a specific error message during the compilation phase (through some static
asserts).

For basic and window-based operators, the functional logic, as well as the key extractor and the
closing logic can be provided as functions, lambdas or functor objects providing operator() with
the right signatures.

For GPU operators, the functional logic and the key extractor logic must be provided as a __host__
__device__ lambda or through a functor object exposing a __host__ __device__ operator() method
with the right signatures.

SOURCE
------
void(Source_Shipper<tuple_t> &);
void(Source_Shipper<tuple_t> &, RuntimeContext &);

KAFKA_SOURCE
------------
bool(std::optional<std::reference_wrapper<RdKafka::Message>>, Source_Shipper<result_t> &);
bool(std::optional<std::reference_wrapper<RdKafka::Message>>, Source_Shipper<result_t> &, KafkaRuntimeContext &);

FILTER
------
bool(tuple_t &);
bool(tuple_t &, RuntimeContext &);

FILTER_GPU
----------
__host__ __device__ bool(tuple_t &);
__host__ __device__ bool(tuple_t &, state_t &);

P_FILTER
--------
bool(tuple_t &, state_t &);
bool(tuple_t &, state_t &, RuntimeContext &);

MAP
---
void(tuple_t &);
void(tuple_t &, RuntimeContext &);
result_t(const tuple_t &);
result_t(const tuple_t &, RuntimeContext &);

MAP_GPU
-------
__host__ __device__ void(tuple_t &);
__host__ __device__ void(tuple_t &, state_t &);

P_MAP
-----
void(tuple_t &, state_t &);
void(tuple_t &, state_t &, RuntimeContext &);
result_t(const tuple_t &, state_t &);
result_t(const tuple_t &, state_t &, RuntimeContext &);

FLATMAP
-------
void(const tuple_t &, Shipper<result_t> &);
void(const tuple_t &, Shipper<result_t> &, RuntimeContext &);

P_FLATMAP
---------
void(const tuple_t &, state_t &, Shipper<result_t> &);
void(const tuple_t &, state_t &, Shipper<result_t> &, RuntimeContext &);

REDUCE
------
void(const tuple_t &, result_t &);
void(const tuple_t &, result_t &, RuntimeContext &);

REDUCE_GPU
----------
__host__ __device__ tuple_t(const tuple_t &, const tuple_t &);

P_REDUCE
--------
void(const tuple_t &, result_t &);
void(const tuple_t &, result_t &, RuntimeContext &);

KEYED_WINDOWS
-------------
void(const Iterable<tuple_t> &, result_t &);
void(const Iterable<tuple_t> &, result_t &, RuntimeContext &);
void(const tuple_t &, result_t &);
void(const tuple_t &, result_t &, RuntimeContext &);

P_KEYED_WINDOWS
---------------
void(const Iterable<tuple_t> &, result_t &);
void(const Iterable<tuple_t> &, result_t &, RuntimeContext &);
void(const tuple_t &, result_t &);
void(const tuple_t &, result_t &, RuntimeContext &);

PARALLEL_WINDOWS
----------------
void(const Iterable<tuple_t> &, result_t &);
void(const Iterable<tuple_t> &, result_t &, RuntimeContext &);
void(const tuple_t &, result_t &);
void(const tuple_t &, result_t &, RuntimeContext &);

PANED_WINDOWS
-------------
The corresponding builder needs two parameters (for the PLQ and WLQ logics) with the following accepted signatures:

 * PLQ
    void(const Iterable<tuple_t> &, tuple_t &);
    void(const Iterable<tuple_t> &, tuple_t &, RuntimeContext &);
    void(const tuple_t &, tuple_t &);
    void(const tuple_t &, tuple_t &, RuntimeContext &);

 * WLQ
    void(const Iterable<tuple_t> &, result_t &);
    void(const Iterable<tuple_t> &, result_t &, RuntimeContext &);
    void(const tuple_t &, result_t &);
    void(const tuple_t &, result_t &, RuntimeContext &);

MAPREDUCE_WINDOWS
-----------------
The corresponding builder needs two parameters (for the MAP and REDUCE logics) with the following accepted signatures:

 * MAP
    void(const Iterable<tuple_t> &, tuple_t &);
    void(const Iterable<tuple_t> &, tuple_t &, RuntimeContext &);
    void(const tuple_t &, tuple_t &);
    void(const tuple_t &, tuple_t &, RuntimeContext &);

 * REDUCE
    void(const Iterable<tuple_t> &, result_t &);
    void(const Iterable<tuple_t> &, result_t &, RuntimeContext &);
    void(const tuple_t &, result_t &);
    void(const tuple_t &, result_t &, RuntimeContext &);

FFAT_Windows
------------
The corresponding builder needs two parameters (for the lift and combine logics) with the following accepted signatures:

 * Lift
    void(const tuple_t &, result_t &);
    void(const tuple_t &, result_t &, RuntimeContext &);

 * Combine
    void(const result_t &, const result_t &, result_t &);
    void(const result_t &, const result_t &, result_t &, RuntimeContext &);

FFAT_Windows_GPU
----------------
The corresponding builder needs two parameters (for the lift and combine logics) with the following accepted signatures:

 * Lift
    __host__ __device__ void(const tuple_t &, result_t &);

 * Combine
    __host__ __device__ void(const result_t &, const result_t &, result_t &);

SINK
----
void(std::optional<tuple_t> &);
void(std::optional<tuple_t> &, RuntimeContext &);
void(std::optional<std::reference_wrapper<tuple_t>>);
void(std::optional<std::reference_wrapper<tuple_t>>, RuntimeContext &);

P_SINK
------
void(std::optional<tuple_t> &, state_t &);
void(std::optional<tuple_t> &, state_t &, RuntimeContext &);
void(std::optional<std::reference_wrapper<tuple_t>>, state_t &);
void(std::optional<std::reference_wrapper<tuple_t>>, state_t &, RuntimeContext &);

KAFKA_SINK
----------
wf::wf_kafka_sink_msg(tuple_t &);
wf::wf_kafka_sink_msg(tuple_t &, KafkaRuntimeContext &);

CLOSING LOGIC
-------------
void(RuntimeContext &);

CLOSING LOGIC (Kafka Operators)
-------------------------------
void(KafkaRuntimeContext &);

KEY EXTRACTOR
-------------
key_t(const tuple_t &); -> for CPU operators
__host__ __device__ key_t(const tuple_t &); // for GPU operators

Nota bene: for GPU operators, the user must provide a __device__ implementation of
operator()== and operator()< functions defined for the key type key_t.

SPLITTING LOGIC
---------------
integral_t(const tuple_t &);
std::vector<integral_t>(const tuple_t &);
integral_t(tuple_t &);
std::vector<integral_t>(tuple_t &);

Nota bene: integral_t is any C++ integral type (e.g., short, int, long, and so forth).
